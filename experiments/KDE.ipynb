{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import (\n",
    "    KernelDensity,\n",
    "    KDTree,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    RobustScaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_self_density(d, n):\n",
    "    return scipy.stats.multivariate_normal.pdf(\n",
    "        np.zeros(d), \n",
    "        mean=np.zeros(d), \n",
    "        cov=np.identity(d)) / n;\n",
    "def estimate_kde_bw(data):\n",
    "    q3 = np.percentile(data, 75, axis=0)\n",
    "    q1 = np.percentile(data, 25, axis=0)\n",
    "    iqr = q3 - q1\n",
    "    bw = iqr * (data.shape[0])**(-1.0/(data.shape[1]+4))\n",
    "    return bw\n",
    "def get_scores(data, numScore=None, tol=0, bw=None):\n",
    "    print(\"Starting\", flush=True)\n",
    "    trainstart = time.time()\n",
    "    if bw is None:\n",
    "        bw = estimate_kde_bw(data)\n",
    "    if numScore is None:\n",
    "        numScore = len(data)\n",
    "    print(\"BW calculated\", flush=True)\n",
    "    scaled_data = data / bw\n",
    "    \n",
    "    # Normalized Computations\n",
    "    kde = KernelDensity(\n",
    "        bandwidth=1,\n",
    "        kernel='gaussian',\n",
    "        algorithm='kd_tree',\n",
    "        rtol=tol,\n",
    "    )\n",
    "    kde.fit(scaled_data)\n",
    "    print(\"Trained\", flush=True)\n",
    "    print(\"Trained in {}\".format(time.time()-trainstart), flush=True)\n",
    "    scorestart = time.time()\n",
    "    scores = np.exp(kde.score_samples(scaled_data[:numScore]))\n",
    "    print(\"Scored\", flush=True)\n",
    "    print(\"Scored in {}\".format(time.time()-scorestart), flush=True)\n",
    "    \n",
    "    self_density = get_self_density(data.shape[1], data.shape[0])\n",
    "    scores_minus_self = scores - self_density\n",
    "    \n",
    "    # Denormalize\n",
    "    denorm_scores = scores_minus_self / np.prod(bw)\n",
    "    return denorm_scores\n",
    "def compare_outliers(scores1, scores2):\n",
    "    cut1 = np.percentile(scores1, 1.0)\n",
    "    flag1 = scores1 < cut1\n",
    "    \n",
    "    cut2 = np.percentile(scores2, 1.0)\n",
    "    flag2 = scores2 < cut2\n",
    "    return np.sum(flag1 & flag2) / np.sum(flag1 | flag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy = pd.read_csv(\"../us_energy_1p0_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_csv(\"../taxi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perf + Jaccard Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmarks(df, ns, numScores, tols, dims):\n",
    "    timings = {}\n",
    "    scores = {}\n",
    "    combinations = itertools.product(ns, numScores, tols, dims)\n",
    "    for t in combinations:\n",
    "        n = t[0]\n",
    "        numScore = t[1]\n",
    "        tol = t[2]\n",
    "        dim = t[3]\n",
    "        print(\"n: {}, numScore: {}, tol: {}, dim: {}\".format(n, numScore, tol, dim))\n",
    "        columns = list(range(dim))\n",
    "        data = df[columns].iloc[:n].values\n",
    "        start = time.time()\n",
    "        scores[t] = get_scores(data, numScore=numScore, tol=tol)\n",
    "        elapsed = time.time() - start\n",
    "        print(\"Elapsed: {}\".format(elapsed))\n",
    "        timings[t] = elapsed\n",
    "    return {\"timings\": timings, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perf Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 500000, numScore: 5000, tol: 0.0, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 3.829257011413574\n",
      "Scored\n",
      "Scored in 212.3846960067749\n",
      "Elapsed: 216.21685004234314\n",
      "n: 500000, numScore: 5000, tol: 0.0, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 4.26601505279541\n",
      "Scored\n",
      "Scored in 274.46328496932983\n",
      "Elapsed: 278.73914909362793\n",
      "n: 500000, numScore: 5000, tol: 0.0, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 46.50823497772217\n",
      "Scored\n",
      "Scored in 314.4873068332672\n",
      "Elapsed: 361.0077340602875\n",
      "n: 500000, numScore: 5000, tol: 0.1, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 5.352800130844116\n",
      "Scored\n",
      "Scored in 58.92997694015503\n",
      "Elapsed: 64.28789591789246\n",
      "n: 500000, numScore: 5000, tol: 0.1, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 6.848196029663086\n",
      "Scored\n",
      "Scored in 79.82740187644958\n",
      "Elapsed: 86.68513584136963\n",
      "n: 500000, numScore: 5000, tol: 0.1, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Trained in 45.6171441078186\n",
      "Scored\n",
      "Scored in 76.96474409103394\n",
      "Elapsed: 122.59193396568298\n"
     ]
    }
   ],
   "source": [
    "presults = run_benchmarks(\n",
    "    df=energy,\n",
    "    ns=[500000],\n",
    "    numScores=[5000],\n",
    "    tols=[0.0,0.1],\n",
    "    dims=[2,4,8]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10000, tol: 0.0, dim: 1\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 4.1302809715271\n",
      "n: 10000, tol: 0.0, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 3.8664679527282715\n",
      "n: 10000, tol: 0.0, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 4.413316011428833\n",
      "n: 10000, tol: 0.0, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 5.624083042144775\n",
      "n: 10000, tol: 0.1, dim: 1\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 1.5577480792999268\n",
      "n: 10000, tol: 0.1, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 1.5478770732879639\n",
      "n: 10000, tol: 0.1, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 2.051440954208374\n",
      "n: 10000, tol: 0.1, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 2.9179069995880127\n",
      "n: 50000, tol: 0.0, dim: 1\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 127.07230186462402\n",
      "n: 50000, tol: 0.0, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 122.14469289779663\n",
      "n: 50000, tol: 0.0, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 131.79677200317383\n",
      "n: 50000, tol: 0.0, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 198.65502095222473\n",
      "n: 50000, tol: 0.1, dim: 1\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 38.09627103805542\n",
      "n: 50000, tol: 0.1, dim: 2\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 38.75493597984314\n",
      "n: 50000, tol: 0.1, dim: 4\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 42.627718925476074\n",
      "n: 50000, tol: 0.1, dim: 8\n",
      "Starting\n",
      "BW calculated\n",
      "Trained\n",
      "Scored\n",
      "Elapsed: 72.32149314880371\n"
     ]
    }
   ],
   "source": [
    "results = run_benchmarks(\n",
    "    data=energy,\n",
    "    ns=[10000,50000],\n",
    "    tols=[0.0,0.1],\n",
    "    dims=[1,2,4,8]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"energy_benchmark.pickle\", 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"energy_benchmark.pickle\", 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity between 0.0 and 0.1 for d2: 0.9801980198019802\n",
      "Jaccard similarity between 0.0 and 0.1 for d4: 0.9801980198019802\n",
      "Jaccard similarity between 0.0 and 0.1 for d8: 0.9157088122605364\n"
     ]
    }
   ],
   "source": [
    "for d in [2,4,8]:\n",
    "    jaccard = compare_outliers(\n",
    "        results[\"scores\"][(50000,0.0,d)],\n",
    "        results[\"scores\"][(50000,0.1,d)]\n",
    "    )\n",
    "    print(\"Jaccard similarity between 0.0 and 0.1 for d{}: {}\".format(\n",
    "         d,\n",
    "         jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"/Users/egan/Documents/Projects/tKDE/experiments/end2end/scores/\"\n",
    "filenames = {\n",
    "    (50000, 0.01, 2): \"energy_n50_d2_tol1.csv\",\n",
    "    (50000, 0.01, 4): \"energy_n50_d4_tol1.csv\",\n",
    "    (50000, 0.01, 8): \"energy_n50_d8_tol1.csv\",\n",
    "    (50000, 0.1, 2): \"energy_n50_d2_tol10.csv\",\n",
    "    (50000, 0.1, 4): \"energy_n50_d4_tol10.csv\",\n",
    "    (50000, 0.1, 8): \"energy_n50_d8_tol10.csv\"\n",
    "}\n",
    "files = {k: prefix+filenames[k] for k in filenames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity between exact and (50000, 0.01, 4): 0.9960079840319361\n",
      "Jaccard similarity between exact and (50000, 0.1, 2): 0.9880715705765407\n",
      "Jaccard similarity between exact and (50000, 0.1, 4): 0.9880715705765407\n",
      "Jaccard similarity between exact and (50000, 0.01, 2): 1.0\n",
      "Jaccard similarity between exact and (50000, 0.1, 8): 0.9960079840319361\n",
      "Jaccard similarity between exact and (50000, 0.01, 8): 0.9960079840319361\n"
     ]
    }
   ],
   "source": [
    "for k,f in files.items():\n",
    "    densities = pd.read_csv(f, header=None).values.flatten()\n",
    "    n=k[0]\n",
    "    d=k[2]\n",
    "    jaccard = compare_outliers(\n",
    "        results[\"scores\"][(n,0.0,d)],\n",
    "        densities\n",
    "    )\n",
    "    print(\"Jaccard similarity between exact and {}: {}\".format(\n",
    "         k,\n",
    "         jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
