{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import (\n",
    "    KernelDensity,\n",
    "    KDTree,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    RobustScaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_kde_bw(data):\n",
    "    q3 = np.percentile(data, 75, axis=0)\n",
    "    q1 = np.percentile(data, 25, axis=0)\n",
    "    iqr = q3 - q1\n",
    "    bw = iqr * (data.shape[0])**(-1.0/(data.shape[1]+4))\n",
    "    return bw\n",
    "def get_scores(data, numScore=None, k=10, bw=None):\n",
    "    print(\"Starting\", flush=True)\n",
    "    trainstart = time.time()\n",
    "    if bw is None:\n",
    "        bw = estimate_kde_bw(data)\n",
    "    if numScore is None:\n",
    "        numScore = len(data)\n",
    "    print(\"BW calculated {}\".format(bw), flush=True)\n",
    "    scaled_data = data / bw\n",
    "    \n",
    "    # Normalized Computations\n",
    "    kdtree = KDTree(scaled_data)\n",
    "    print(\"Trained\", flush=True)\n",
    "    print(\"Trained in {}\".format(time.time()-trainstart), flush=True)\n",
    "    scorestart = time.time()\n",
    "    scores,_ = kdtree.query(\n",
    "        scaled_data[:numScore],\n",
    "        k=k,\n",
    "        dualtree=True\n",
    "    )\n",
    "    \n",
    "    print(\"Scored {}\".format(numScore), flush=True)\n",
    "    print(\"Scored in {}\".format(time.time()-scorestart), flush=True)\n",
    "        \n",
    "    # Denormalize\n",
    "    return scores[:,k-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy = pd.read_csv(\"../data/us_energy_1p0_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "BW calculated [ 23.25610346   5.44144229]\n",
      "Trained\n",
      "Trained in 24.151832103729248\n",
      "Scored 1000000\n",
      "Scored in 71.62647700309753\n"
     ]
    }
   ],
   "source": [
    "scores = get_scores(energy[[0,1]].iloc[:1000000], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5295806120391768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(scores, 99.0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
